name: Flikary.dev Performance Monitoring

on:
  push:
    branches: [main]
    paths:
      - "src/**"
      - "public/**"
      - "astro.config.mjs"
      - "package.json"
      - "package-lock.json"
      - "performance-config.json"
      - "tailwind.config.js"
      - "tsconfig.json"

  # 24시간 동안 실행 안된 경우 오전 4시에 실행 (KST 기준)
  schedule:
    - cron: "0 19 * * *" # UTC 19:00 = KST 04:00

  workflow_dispatch:
    inputs:
      test_config:
        description: "테스트 구성"
        required: true
        default: "quick"
        type: choice
        options:
          - "quick"
          - "comprehensive"
          - "blog_focus"
      environment:
        description: "테스트 환경"
        required: true
        default: "production"
        type: choice
        options:
          - "local"
          - "staging"
          - "production"
      force_run:
        description: "강제 실행 (파일 변경 여부 무시)"
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: "18"
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  GITHUB_EVENT_NAME: ${{ github.event_name }}
  GITHUB_API_URL: ${{ github.api_url }}
  GITHUB_REPOSITORY: ${{ github.repository }}
  GITHUB_SHA: ${{ github.sha }}
  GITHUB_REF_NAME: ${{ github.ref_name }}
  GITHUB_ACTOR: ${{ github.actor }}
  GITHUB_RUN_NUMBER: ${{ github.run_number }}
  INPUT_FORCE_RUN: ${{ inputs.force_run }}
  INPUT_TEST_CONFIG: ${{ inputs.test_config }}
  INPUT_ENVIRONMENT: ${{ inputs.environment }}

jobs:
  check-execution-needed:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      config_name: ${{ steps.config.outputs.config_name }}
      environment: ${{ steps.config.outputs.environment }}
      test_urls: ${{ steps.urls.outputs.test_urls }}
      page_names: ${{ steps.urls.outputs.page_names }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Check if performance test should run
        id: check
        run: ./scripts/performance/check-execution.sh

      - name: Determine test configuration
        id: config
        run: ./scripts/performance/determine-config.sh

      - name: Generate test URLs from config
        id: urls
        run: |
          ./scripts/performance/generate-urls.sh \
            "${{ steps.config.outputs.config_name }}" \
            "${{ steps.config.outputs.environment }}"

  performance-test:
    needs: check-execution-needed
    if: needs.check-execution-needed.outputs.should_run == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: Install dependencies
        run: |
          echo "📦 Installing dependencies..."
          npm ci

      - name: Build Astro site
        if: needs.check-execution-needed.outputs.environment == 'local'
        run: |
          echo "🔨 Building Astro site..."
          npm run build

      - name: Start local preview server
        if: needs.check-execution-needed.outputs.environment == 'local'
        run: |
          echo "🚀 Starting Astro preview server..."
          npm run preview &

          # 서버 준비 대기
          echo "⏳ Waiting for Astro server to be ready..."
          for i in {1..30}; do
            if curl -f http://localhost:4321 >/dev/null 2>&1; then
              echo "✅ Astro server is ready after ${i} attempts"
              break
            else
              echo "⏳ Attempt $i: Server not ready yet..."
              sleep 2
            fi
            
            if [ $i -eq 30 ]; then
              echo "❌ Astro server failed to start after 60 seconds"
              exit 1
            fi
          done

      - name: Install Lighthouse
        run: |
          echo "💡 Installing Lighthouse..."
          npm install -g lighthouse

      - name: Run comprehensive performance tests
        run: |
          ./scripts/performance/run-lighthouse.sh \
            '${{ needs.check-execution-needed.outputs.test_urls }}' \
            '${{ needs.check-execution-needed.outputs.page_names }}' \
            "${{ needs.check-execution-needed.outputs.config_name }}" \
            "${{ needs.check-execution-needed.outputs.environment }}"

      - name: Collect Web Vitals (Real User Data)
        run: |
          echo "🌍 Collecting Web Vitals data..."
          node ./scripts/performance/collect-web-vitals.js '${{ needs.check-execution-needed.outputs.test_urls }}'

      - name: Check performance thresholds and determine if should fail
        id: threshold_check
        run: ./scripts/performance/check-thresholds.sh

      - name: Generate performance report
        run: |
          ./scripts/performance/generate-report.sh \
            "${{ needs.check-execution-needed.outputs.config_name }}" \
            "${{ needs.check-execution-needed.outputs.environment }}" \
            "${{ steps.threshold_check.outputs.should_fail }}" \
            "${{ steps.threshold_check.outputs.failure_reasons }}"

      - name: Commit performance report
        run: |
          git config --local user.email "performance-bot@flikary.dev"
          git config --local user.name "Flikary Performance Bot"

          git add report/
          git add performance-data/

          if ! git diff --staged --quiet; then
            git commit -m "📊 Performance report $(date +%Y-%m-%d_%H-%M-%S)
            
            🎯 Config: ${{ needs.check-execution-needed.outputs.config_name }}
            🌐 Environment: ${{ needs.check-execution-needed.outputs.environment }}
            📦 Commit: ${GITHUB_SHA:0:7}
            🌿 Branch: ${{ github.ref_name }}
            🔨 Build: #${{ github.run_number }}
            $(if [ "${{ steps.threshold_check.outputs.should_fail }}" = "true" ]; then echo "🚨 Threshold violations detected"; else echo "✅ All thresholds passed"; fi)"
            
            git push
            echo "✅ Performance report committed to repository"
          else
            echo "📭 No new performance data to commit"
          fi

      - name: Performance summary for GitHub Actions
        run: |
          echo "## 🎯 Flikary.dev Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Config**: ${{ needs.check-execution-needed.outputs.config_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: ${{ needs.check-execution-needed.outputs.environment }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: \`${GITHUB_SHA:0:7}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.threshold_check.outputs.should_fail }}" = "true" ]; then
            echo "### 🚨 Performance Issues Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "${{ steps.threshold_check.outputs.failure_reasons }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Action Result**: This workflow will fail due to performance threshold violations." >> $GITHUB_STEP_SUMMARY
          else
            echo "### ✅ All Performance Thresholds Passed" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Action Result**: All performance metrics are within acceptable thresholds." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📄 **Detailed Report**: \`report/performance-report-$(date +%Y-%m-%d_%H-%M-%S).md\`" >> $GITHUB_STEP_SUMMARY

      - name: Fail if performance thresholds violated
        if: steps.threshold_check.outputs.should_fail == 'true'
        run: |
          echo "🚨 Performance thresholds were violated!"
          echo ""
          echo "Failure reasons:"
          echo "${{ steps.threshold_check.outputs.failure_reasons }}"
          echo ""
          echo "📄 Check the detailed report in the report/ directory for more information."
          echo "🔧 Review the performance-config.json file to adjust thresholds if needed."
          exit 1

  skip-notification:
    needs: check-execution-needed
    if: needs.check-execution-needed.outputs.should_run == 'false'
    runs-on: ubuntu-latest
    steps:
      - name: Skip notification
        run: |
          echo "## ⏭️ Performance Test Skipped" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "**Reason**: Performance test already executed successfully within the last 24 hours" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Reason**: No performance-impacting files were changed" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Next scheduled run**: Daily at 4:00 AM KST if no successful runs in 24 hours" >> $GITHUB_STEP_SUMMARY
